{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers as reg"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 3,
>>>>>>> Stashed changes
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 254, 254, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 125, 125, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 60, 60, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               14745856  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 14,890,115\n",
      "Trainable params: 14,889,091\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "Found 3600 images belonging to 3 classes.\n",
      "Found 1200 images belonging to 3 classes.\n",
      "Epoch 1/50\n",
      "225/225 [==============================] - 1140s 5s/step - loss: 37.3515 - acc: 0.5142 - val_loss: 24.7540 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "225/225 [==============================] - 1055s 5s/step - loss: 17.1062 - acc: 0.5836 - val_loss: 15.8769 - val_acc: 0.4283\n",
      "Epoch 3/50\n",
      "225/225 [==============================] - 674s 3s/step - loss: 13.2651 - acc: 0.6389 - val_loss: 12.5816 - val_acc: 0.6283\n",
      "Epoch 4/50\n",
      "225/225 [==============================] - 654s 3s/step - loss: 11.5097 - acc: 0.6706 - val_loss: 11.3711 - val_acc: 0.5342\n",
      "Epoch 5/50\n",
      "225/225 [==============================] - 655s 3s/step - loss: 10.5553 - acc: 0.7114 - val_loss: 11.4966 - val_acc: 0.4892\n",
      "Epoch 6/50\n",
      "225/225 [==============================] - 658s 3s/step - loss: 9.5750 - acc: 0.7319 - val_loss: 9.1974 - val_acc: 0.7233\n",
      "Epoch 7/50\n",
      "225/225 [==============================] - 672s 3s/step - loss: 8.9905 - acc: 0.7369 - val_loss: 8.8165 - val_acc: 0.7792\n",
      "Epoch 8/50\n",
      "225/225 [==============================] - 667s 3s/step - loss: 8.3759 - acc: 0.7636 - val_loss: 8.8547 - val_acc: 0.5708\n",
      "Epoch 9/50\n",
      "225/225 [==============================] - 665s 3s/step - loss: 7.9923 - acc: 0.7528 - val_loss: 10.2511 - val_acc: 0.3950\n",
      "Epoch 10/50\n",
      "225/225 [==============================] - 886s 4s/step - loss: 7.5963 - acc: 0.7681 - val_loss: 7.2765 - val_acc: 0.8183\n",
      "Epoch 11/50\n",
      "225/225 [==============================] - 1285s 6s/step - loss: 7.2247 - acc: 0.7819 - val_loss: 7.6013 - val_acc: 0.6183\n",
      "Epoch 12/50\n",
<<<<<<< Updated upstream
      " 62/225 [=======>......................] - ETA: 14:14 - loss: 6.7299 - acc: 0.8085"
=======
      "225/225 [==============================] - 999s 4s/step - loss: 6.7794 - acc: 0.7869 - val_loss: 6.8974 - val_acc: 0.7708\n",
      "Epoch 13/50\n",
      "225/225 [==============================] - 1219s 5s/step - loss: 6.6317 - acc: 0.7831 - val_loss: 6.1372 - val_acc: 0.8525\n",
      "Epoch 14/50\n",
      "225/225 [==============================] - 1201s 5s/step - loss: 6.2007 - acc: 0.8003 - val_loss: 6.2131 - val_acc: 0.7767\n",
      "Epoch 15/50\n",
      "225/225 [==============================] - 1190s 5s/step - loss: 6.0540 - acc: 0.7972 - val_loss: 6.1019 - val_acc: 0.7375\n",
      "Epoch 16/50\n",
      "225/225 [==============================] - 1213s 5s/step - loss: 5.7794 - acc: 0.8083 - val_loss: 5.7958 - val_acc: 0.7625\n",
      "Epoch 17/50\n",
      "225/225 [==============================] - 1212s 5s/step - loss: 5.6747 - acc: 0.8008 - val_loss: 5.8251 - val_acc: 0.7433\n",
      "Epoch 18/50\n",
      "225/225 [==============================] - 1209s 5s/step - loss: 5.4547 - acc: 0.8086 - val_loss: 5.5799 - val_acc: 0.8225\n",
      "Epoch 19/50\n",
      "225/225 [==============================] - 1200s 5s/step - loss: 5.2735 - acc: 0.8100 - val_loss: 5.9841 - val_acc: 0.6092\n",
      "Epoch 20/50\n",
      "225/225 [==============================] - 1214s 5s/step - loss: 5.1039 - acc: 0.8228 - val_loss: 4.8280 - val_acc: 0.8767\n",
      "Epoch 21/50\n",
      "225/225 [==============================] - 926s 4s/step - loss: 4.9080 - acc: 0.8275 - val_loss: 5.3123 - val_acc: 0.7383\n",
      "Epoch 22/50\n",
      "225/225 [==============================] - 657s 3s/step - loss: 4.7973 - acc: 0.8206 - val_loss: 4.7290 - val_acc: 0.8133\n",
      "Epoch 23/50\n",
      "225/225 [==============================] - 654s 3s/step - loss: 4.6125 - acc: 0.8269 - val_loss: 4.5085 - val_acc: 0.8450\n",
      "Epoch 24/50\n",
      "225/225 [==============================] - 657s 3s/step - loss: 4.4557 - acc: 0.8222 - val_loss: 4.6559 - val_acc: 0.7183\n",
      "Epoch 25/50\n",
      "225/225 [==============================] - 659s 3s/step - loss: 4.3949 - acc: 0.8186 - val_loss: 4.1242 - val_acc: 0.8992\n",
      "Epoch 26/50\n",
      "225/225 [==============================] - 664s 3s/step - loss: 4.2504 - acc: 0.8292 - val_loss: 4.1945 - val_acc: 0.8333\n",
      "Epoch 27/50\n",
      "225/225 [==============================] - 666s 3s/step - loss: 4.1552 - acc: 0.8219 - val_loss: 4.5219 - val_acc: 0.7275\n",
      "Epoch 28/50\n",
      "225/225 [==============================] - 670s 3s/step - loss: 4.0704 - acc: 0.8281 - val_loss: 4.3847 - val_acc: 0.6517\n",
      "Epoch 29/50\n",
      "225/225 [==============================] - 676s 3s/step - loss: 3.9168 - acc: 0.8447 - val_loss: 3.9202 - val_acc: 0.8067\n",
      "Epoch 30/50\n",
      "225/225 [==============================] - 683s 3s/step - loss: 3.8703 - acc: 0.8414 - val_loss: 3.7273 - val_acc: 0.8867\n",
      "Epoch 31/50\n",
      "225/225 [==============================] - 687s 3s/step - loss: 3.7815 - acc: 0.8400 - val_loss: 3.9655 - val_acc: 0.7608\n",
      "Epoch 32/50\n",
      "225/225 [==============================] - 688s 3s/step - loss: 3.7500 - acc: 0.8319 - val_loss: 3.8358 - val_acc: 0.8142\n",
      "Epoch 33/50\n",
      "225/225 [==============================] - 688s 3s/step - loss: 3.6211 - acc: 0.8442 - val_loss: 3.8537 - val_acc: 0.7608\n",
      "Epoch 34/50\n",
      "225/225 [==============================] - 688s 3s/step - loss: 3.6114 - acc: 0.8425 - val_loss: 4.8289 - val_acc: 0.5875\n",
      "Epoch 35/50\n",
      "225/225 [==============================] - 685s 3s/step - loss: 3.5384 - acc: 0.8369 - val_loss: 3.5562 - val_acc: 0.8292\n",
      "Epoch 36/50\n",
      "225/225 [==============================] - 683s 3s/step - loss: 3.4673 - acc: 0.8544 - val_loss: 3.6177 - val_acc: 0.7792\n",
      "Epoch 37/50\n",
      "225/225 [==============================] - 684s 3s/step - loss: 3.4309 - acc: 0.8456 - val_loss: 3.2597 - val_acc: 0.8925\n",
      "Epoch 38/50\n",
      "225/225 [==============================] - 686s 3s/step - loss: 3.3643 - acc: 0.8464 - val_loss: 3.5618 - val_acc: 0.7708\n",
      "Epoch 39/50\n",
      "225/225 [==============================] - 684s 3s/step - loss: 3.3274 - acc: 0.8417 - val_loss: 3.3180 - val_acc: 0.8400\n",
      "Epoch 40/50\n",
      "225/225 [==============================] - 689s 3s/step - loss: 3.3009 - acc: 0.8381 - val_loss: 3.2712 - val_acc: 0.8200\n",
      "Epoch 41/50\n",
      "225/225 [==============================] - 1247s 6s/step - loss: 3.2582 - acc: 0.8456 - val_loss: 3.5212 - val_acc: 0.7650\n",
      "Epoch 42/50\n",
      "225/225 [==============================] - 1303s 6s/step - loss: 3.1591 - acc: 0.8528 - val_loss: 3.2185 - val_acc: 0.8350\n",
      "Epoch 43/50\n",
      "225/225 [==============================] - 902s 4s/step - loss: 3.1076 - acc: 0.8500 - val_loss: 3.8641 - val_acc: 0.5667\n",
      "Epoch 44/50\n",
      "202/225 [=========================>....] - ETA: 1:57 - loss: 3.0940 - acc: 0.8484"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cfe1a270c9fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                     validation_steps=nb_validation_samples // batch_size) \n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "global_start=datetime.now()\n",
    "\n",
    "#Dimensions of our flicker images is 256 X 256\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "#Declaration of parameters needed for training and validation\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 3600 #1200 training samples for each class\n",
    "nb_validation_samples = 1200 #400 training samples for each class\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "#First convolution layer\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001),input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Second convolution layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001),input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Third convolution layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001),input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Flatten the outputs of the convolution layer into a 1D contigious array\n",
    "model.add(Flatten())\n",
    "\n",
    "#Add a fully connected layer containing 128 neurons, use activation as relu and a dropout rate of 0.5\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.4))\n",
    "\n",
    "#Add another fully connected layer containing 128 neurons, use activation as relu and a dropout rate of 0.5\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.4))\n",
    "\n",
    "#Add the ouput layer containing 3 neurons, because we have 3 categories\n",
    "model.add(Dense(3, activation='softmax',kernel_initializer='glorot_uniform'))\n",
    "\n",
    "optim=RMSprop(lr=0.0001, epsilon=1e-8, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optim,metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#We will use the below code snippet for data augmentation on the training data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.4,\n",
    "                                   zoom_range=0.4,\n",
    "                                   vertical_flip=True,\n",
    "                                   rotation_range=30,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "#We won't augment the test data. We will just use ImageDataGenerator to rescale.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size=(img_width, img_height),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=nb_train_samples // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=nb_validation_samples // batch_size) \n",
    "\n",
    "\n",
    "model.save_weights('cnn_from_scratch_weights.h5') \n",
    "model.save('cnn_from_scratch_model.h5') #Load using: model = load_model('cnn_from_scratch_weights.h5') from keras.models import load_model\n",
    "print(\"Time taken to train the baseline model from scratch: \",datetime.now()-global_start)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#This function is used to plot/update the train and test loss after each epoch.\n",
    "def plt_dynamic_loss(x, vy, ty, ax, colors=['b']):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()\n",
    "\n",
    "\n",
    "#Get model history\n",
    "history=model.history\n",
    "\n",
    "#Plot train vs test loss\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('Epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "#List of epoch numbers\n",
    "x = list(range(1,epochs+1))\n",
    "\n",
    "#Display the loss\n",
    "val_loss = history.history['val_loss'] #Validation Loss\n",
    "loss = history.history['loss'] #Training Loss\n",
    "plt_dynamic_loss(x, val_loss, loss, ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
