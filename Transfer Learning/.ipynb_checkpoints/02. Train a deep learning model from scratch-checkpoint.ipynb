{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers as reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "global_start=datetime.now()\n",
    "\n",
    "#Dimensions of our flicker images is 256 X 256\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "#Declaration of parameters needed for training and validation\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 3600 #1200 training samples for each class\n",
    "nb_validation_samples = 1200 #400 training samples for each class\n",
    "epochs = 40\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "#First convolution layer\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001),input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Second convolution layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001),input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Third convolution layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001),input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Flatten the outputs of the convolution layer into a 1D contigious array\n",
    "model.add(Flatten())\n",
    "\n",
    "#Add a fully connected layer containing 128 neurons, use activation as relu and a dropout rate of 0.5\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.4))\n",
    "\n",
    "#Add another fully connected layer containing 128 neurons, use activation as relu and a dropout rate of 0.5\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.4))\n",
    "\n",
    "#Add the ouput layer containing 3 neurons, because we have 3 categories\n",
    "model.add(Dense(3, activation='softmax',kernel_initializer='glorot_uniform'))\n",
    "\n",
    "optim=RMSprop(lr=0.0001, epsilon=1e-8, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optim,metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#We will use the below code snippet for data augmentation on the training data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.4,\n",
    "                                   zoom_range=0.4,\n",
    "                                   vertical_flip=True,\n",
    "                                   rotation_range=30,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "#We won't augment the test data. We will just use ImageDataGenerator to rescale.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size=(img_width, img_height),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=nb_train_samples // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=nb_validation_samples // batch_size) \n",
    "\n",
    "\n",
    "model.save_weights('cnn_from_scratch_weights.h5') \n",
    "model.save('cnn_from_scratch_model.h5') #Load using: model = load_model('cnn_from_scratch_weights.h5') from keras.models import load_model\n",
    "print(\"Time taken to train the baseline model from scratch: \",datetime.now()-global_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#This function is used to plot/update the train and test loss after each epoch.\n",
    "def plt_dynamic_loss(x, vy, ty, ax, colors=['b']):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()\n",
    "\n",
    "\n",
    "#Get model history\n",
    "history=model.history\n",
    "\n",
    "#Plot train vs test loss\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('Epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "#List of epoch numbers\n",
    "x = list(range(1,epochs+1))\n",
    "\n",
    "#Display the loss\n",
    "val_loss = history.history['val_loss'] #Validation Loss\n",
    "loss = history.history['loss'] #Training Loss\n",
    "plt_dynamic_loss(x, val_loss, loss, ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
