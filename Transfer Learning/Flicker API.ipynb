{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from datetime import datetime as dt\n",
    "global_start = dt.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cur_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What class of images?: birds\n",
      "How many?: 50\n",
      "Flicker folder is already present.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading birds images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|▏         | 1/50 [00:01<00:57,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 2/50 [00:02<00:51,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 3/50 [00:03<00:59,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 4/50 [00:04<00:53,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 5/50 [00:06<01:05,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 6/50 [00:07<00:55,  1.27s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 7/50 [00:10<01:10,  1.64s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 8/50 [00:11<01:05,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 9/50 [00:12<00:59,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 10/50 [00:13<00:53,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 11/50 [00:16<01:09,  1.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 12/50 [00:17<01:02,  1.64s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 13/50 [00:19<00:55,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 14/50 [00:19<00:45,  1.27s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 15/50 [00:20<00:40,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 16/50 [00:21<00:39,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 17/50 [00:22<00:35,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 18/50 [00:23<00:35,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 19/50 [00:25<00:34,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 20/50 [00:26<00:40,  1.35s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 21/50 [00:27<00:35,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 22/50 [00:29<00:33,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 23/50 [00:31<00:40,  1.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 24/50 [00:32<00:33,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 25/50 [00:33<00:32,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 26/50 [00:34<00:32,  1.37s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 27/50 [00:36<00:30,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 28/50 [00:37<00:28,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 29/50 [00:38<00:24,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 30/50 [00:39<00:22,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 31/50 [00:40<00:20,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 32/50 [00:42<00:23,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 33/50 [00:43<00:22,  1.35s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 34/50 [00:45<00:23,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 35/50 [00:47<00:23,  1.59s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 36/50 [00:48<00:19,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 37/50 [00:48<00:16,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 38/50 [00:51<00:20,  1.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 39/50 [00:54<00:22,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 40/50 [00:55<00:17,  1.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 41/50 [00:56<00:13,  1.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 42/50 [00:57<00:11,  1.39s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 43/50 [00:59<00:10,  1.52s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 44/50 [01:00<00:08,  1.35s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 45/50 [01:01<00:06,  1.27s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 46/50 [01:04<00:07,  1.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 47/50 [01:05<00:04,  1.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 48/50 [01:06<00:02,  1.35s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 49/50 [01:07<00:01,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 50/50 [01:09<00:00,  1.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 training images of 'birds' downloaded and saved in folder '/Transfer Learning/flicker/birds'\n"
     ]
    }
   ],
   "source": [
    "def get_images():\n",
    "    \n",
    "    #What categories of images you want to download?\n",
    "    #What's the total of images you want to download?\n",
    "    #Fraction of images you want for test data? (0 to 1)\n",
    "    \n",
    "    import flickrapi\n",
    "    import urllib.request as geturl\n",
    "    from PIL import Image\n",
    "    \n",
    "    category=input(\"What class of images?: \")\n",
    "    n=int(input(\"How many?: \"))\n",
    "            \n",
    "    #Creating the initial directory structures\n",
    "    import os\n",
    "    cur_dir = os.getcwd()\n",
    "    cat_name=cur_dir+'/flicker'+'/{}'.format(category)\n",
    "    if not os.path.isdir(cur_dir+'/flicker'):\n",
    "        os.mkdir(cur_dir+'/flicker')\n",
    "    else:\n",
    "        print(\"Flicker folder is already present.\")\n",
    "        cat_name=cur_dir+'/flicker'+'/{}'.format(category)\n",
    "        \n",
    "    if not os.path.isdir(cat_name):\n",
    "        os.mkdir(cat_name)\n",
    "    else:\n",
    "        print(\"{} folder is already present.\".format(category))\n",
    "\n",
    "    #Using the FlickrAPI key to access flicker \n",
    "    flickr=flickrapi.FlickrAPI('c6a2c45591d4973ff525042472446ca2', '202ffe6f387ce29b', cache=True)\n",
    "    keyword = category\n",
    "    photos = flickr.walk(text=keyword,tag_mode='all',tags=keyword,extras='url_c',per_page=100,sort='relevance')\n",
    "\n",
    "    #Build a list of valid URLS, we will use these URLs to retrieve images\n",
    "    url_lists = []\n",
    "    count=1\n",
    "    for i, photo in enumerate(photos):\n",
    "        url = photo.get('url_c')\n",
    "        if(url!=None):\n",
    "            url_lists.append(url)\n",
    "            count+=1\n",
    "\n",
    "        #Get 'n' valids URLS for 'n' images you want to download\n",
    "        if count > n:\n",
    "            break\n",
    "\n",
    "    #This block actually downloads all the 'n'  images belonging to 'keywords' category \n",
    "    print(\"Downloading {} images...\".format(category))\n",
    "    from tqdm import tqdm\n",
    "    i=1\n",
    "    for url in tqdm(url_lists):\n",
    "        folder = cat_name\n",
    "        geturl.urlretrieve(url, folder+'/{}{}.jpg'.format(category,i))\n",
    "        image = Image.open(folder+'/{}{}.jpg'.format(category,i)) \n",
    "        image = image.resize((256, 256), Image.ANTIALIAS)\n",
    "        image.save(folder+'/{}{}.jpg'.format(category,i))\n",
    "        i+=1\n",
    "\n",
    "    path = folder.split(\"/\")[-3:]\n",
    "    f_path=\"\"\n",
    "    for i in path:\n",
    "        f_path =f_path + \"/\" + i\n",
    "\n",
    "    print(\"{} training images of '{}' downloaded and saved in folder '{}'\".format(len(url_lists),category,f_path))\n",
    "\n",
    "get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
