{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras import applications\n",
    "from datetime import datetime as dt\n",
    "from keras import regularizers as reg\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.externals import joblib\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function to plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function to plot the confusion matrices\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "def plot_confusion_matrix(cm_df, classes, normalize, title):\n",
    "    if normalize:\n",
    "        cm = cm_df.values\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        plt.figure(figsize = (7,7))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Greens)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=90)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        plt.tight_layout()\n",
    "        plt.xlabel('Predicted labels')\n",
    "        plt.ylabel('True labels')\n",
    "    \n",
    "    else:\n",
    "        import seaborn as sn\n",
    "        plt.figure(figsize = (6,5))\n",
    "        ax = sn.heatmap(cm_df, annot=True, fmt='d', cmap=plt.cm.Blues)   #fmt='d' for decimal integer.\n",
    "        ax.set_xlabel(\"Predicted Labels\")\n",
    "        ax.set_ylabel(\"True Labels\")\n",
    "        ax.set_title(title)\n",
    "\n",
    "#Utility function to design the confusion matrix DF\n",
    "def get_confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "    cm_df =  pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])\n",
    "    return cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring general parameters from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensions of our flicker images is 256 X 256\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "#Declaration of parameters needed for training and validation\n",
    "test_data_dir = 'data/test'\n",
    "epochs = 50\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring generator function for the test batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2500 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                                target_size=(img_width, img_height),\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode=None,\n",
    "                                                shuffle=False)\n",
    "\n",
    "nb_test_samples = len(test_generator.filenames) #2500. 500 testing samples for each class  \n",
    "nb_validation_samples = len(test_generator.filenames) #2500. 500 testing samples for each class\n",
    "num_classes = len(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract bottleneck features from test batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"cnn_codes\") if not os.path.isdir(\"cnn_codes\") else None\n",
    "\n",
    "#Get the bottleneck features by  Weights.T * Xi\n",
    "def get_test_bottlebeck_features(model_name):\n",
    "    \n",
    "    start=dt.now()\n",
    "    \n",
    "    #Load the pre trained model from Keras, we will initialize only the convolution layers and ignore the top layers.\n",
    "    if model_name == \"VGG16\":\n",
    "        model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    elif model_name == \"InceptionV3\":\n",
    "        model = applications.InceptionV3(include_top=False, weights='imagenet')\n",
    "    elif model_name == \"ResNet50\": \n",
    "        model = applications.ResNet50(include_top=False, weights='imagenet')\n",
    "    elif model_name == \"InceptionResNetV2\": \n",
    "        model = applications.InceptionResNetV2(include_top=False, weights='imagenet')\n",
    "    elif model_name == \"DenseNet201\": \n",
    "        model = applications.DenseNet201(include_top=False, weights='imagenet')\n",
    "\n",
    "    bottleneck_features_test = model.predict_generator(test_generator, nb_test_samples // batch_size)\n",
    "    np.save('cnn_codes/{}_bottleneck_features_test.npy'.format(model_name),bottleneck_features_test) #bottleneck_features_test is a numpy array\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"Got the test bottleneck features for {} model, in time: \".format(model_name),dt.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got the test bottleneck features for InceptionV3 model, in time:  0:06:18.853306\n",
      "Got the test bottleneck features for VGG16 model, in time:  0:23:09.425068\n",
      "Got the test bottleneck features for ResNet50 model, in time:  0:09:26.531706\n",
      "Got the test bottleneck features for InceptionResNetV2 model, in time:  0:13:40.346079\n",
      "Got the test bottleneck features for DenseNet201 model, in time:  0:15:50.900298\n"
     ]
    }
   ],
   "source": [
    "#Get the test bottleneck features for all the models we have tried\n",
    "get_test_bottlebeck_features(\"InceptionV3\")\n",
    "get_test_bottlebeck_features(\"VGG16\")\n",
    "get_test_bottlebeck_features(\"ResNet50\")\n",
    "get_test_bottlebeck_features(\"InceptionResNetV2\")\n",
    "get_test_bottlebeck_features(\"DenseNet201\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the 3 CNN models\n",
    "#Load the second CNN model\n",
    "#Load the third CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the pretrained models\n",
    "inception_v3 = load_model('models/InceptionV3_bottleneck_features_test.h5')\n",
    "vgg_16 = load_model('models/VGG16_bottleneck_features_test.h5')\n",
    "res_net50 = load_model('models/ResNet50_bottleneck_features_test.h5')\n",
    "inc_res_net_v2 = load_model('models/InceptionResNetV2_bottleneck_features_test.h5')\n",
    "dense_net201 = load_model('models/DenseNet201_bottleneck_features_test.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net201 = load_model('models/densenet201_bottleneck_feats_multi_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dense_net201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e373b742a596>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdense_net201\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "dense_net201.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6bff7b2f487e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdense_net201\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "dense_net201.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
