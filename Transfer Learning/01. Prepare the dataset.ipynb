{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from datetime import datetime as dt\n",
    "global_start = dt.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the initial directory structures\n",
    "import os\n",
    "cur_dir = os.getcwd()\n",
    "train=cur_dir+'/data'+'/train'\n",
    "val=cur_dir+'/data'+'/validation'\n",
    "os.mkdir(cur_dir+'/data')\n",
    "os.mkdir(train)\n",
    "os.mkdir(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(category,n,frac):\n",
    "    \n",
    "    #What categories of images you want to download?\n",
    "    #What's the total of images you want to download?\n",
    "    #Fraction of images you want for test data? (0 to 1)\n",
    "    \n",
    "    import flickrapi\n",
    "    import urllib.request as geturl\n",
    "    from PIL import Image\n",
    "\n",
    "    #Create a folder corresponding to category name, each category will be stored in a different folder\n",
    "    import os\n",
    "    os.mkdir(train+\"/\"+category)\n",
    "    os.mkdir(val+\"/\"+category)\n",
    "\n",
    "    #Using the FlickrAPI key to access flicker \n",
    "    flickr=flickrapi.FlickrAPI('c6a2c45591d4973ff525042472446ca2', '202ffe6f387ce29b', cache=True)\n",
    "    keyword = category\n",
    "    photos = flickr.walk(text=keyword,tag_mode='all',tags=keyword,extras='url_c',per_page=100,sort='relevance')\n",
    "\n",
    "    #Build a list of valid URLS, we will use these URLs to retrieve images\n",
    "    url_lists = []\n",
    "    count=1\n",
    "    for i, photo in enumerate(photos):\n",
    "        url = photo.get('url_c')\n",
    "        if(url!=None):\n",
    "            url_lists.append(url)\n",
    "            count+=1\n",
    "\n",
    "        #Get 'n' valids URLS for 'n' images you want to download\n",
    "        if count > n:\n",
    "            break\n",
    "\n",
    "    #Get training and testing image URLs in two lists        \n",
    "    train_urls = url_lists[0:n-int(frac*len(url_lists))]\n",
    "    test_urls = url_lists[int(n-frac*len(url_lists)):]\n",
    "\n",
    "    #This block actually downloads all the 'n'  images belonging to 'keywords' category \n",
    "    print(\"Downloading training images...\")\n",
    "    from tqdm import tqdm\n",
    "    i=1\n",
    "    for url in tqdm(train_urls):\n",
    "        folder = train+\"/\"+category\n",
    "        geturl.urlretrieve(url, folder+'/{}{}.jpg'.format(category,i))\n",
    "        image = Image.open(folder+'/{}{}.jpg'.format(category,i)) \n",
    "        image = image.resize((256, 256), Image.ANTIALIAS)\n",
    "        image.save(folder+'/{}{}.jpg'.format(category,i))\n",
    "        i+=1\n",
    "\n",
    "    path = folder.split(\"/\")[-3:]\n",
    "    f_path=\"\"\n",
    "    for i in path:\n",
    "        f_path =f_path + \"/\" + i\n",
    "\n",
    "    print(\"{} training images of '{}' downloaded and saved in folder '{}'\".format(len(train_urls),category,f_path))\n",
    "    \n",
    "    i = n-len(test_urls) + 1 # Initialize the counter once again at where we left of\n",
    "\n",
    "    #This block actually downloads all the 'n' images belonging to 'keywords' category \n",
    "    print(\"\\n\\nDownloading validation images...\")\n",
    "    from tqdm import tqdm\n",
    "    for url in tqdm(test_urls):\n",
    "        folder = val+\"/\"+category\n",
    "        geturl.urlretrieve(url, folder+'/{}{}.jpg'.format(category,i))\n",
    "        image = Image.open(folder+'/{}{}.jpg'.format(category,i)) \n",
    "        image = image.resize((256, 256), Image.ANTIALIAS)\n",
    "        image.save(folder+'/{}{}.jpg'.format(category,i))\n",
    "        i+=1\n",
    "\n",
    "    path = folder.split(\"/\")[-3:]\n",
    "    f_path=\"\"\n",
    "    for i in path:\n",
    "        f_path =f_path + \"/\" + i\n",
    "\n",
    "    print(\"{} validation images of '{}' downloaded and saved in folder '{}'\".format(len(test_urls),category,f_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download all the images for horse\n",
    "get_images(\"horse\",1500,0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download all the images for tiger\n",
    "get_images(\"tiger\",1500,0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download all the images for monkey\n",
    "get_images(\"monkey\",1500,0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time taken to download the whole data: \",dt.now()-global_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
