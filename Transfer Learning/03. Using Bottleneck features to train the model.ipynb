{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras import applications\n",
    "from datetime import datetime as dt\n",
    "from keras import regularizers as reg\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_start=dt.now()\n",
    "\n",
    "#Dimensions of our flicker images is 256 X 256\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "#Declaration of parameters needed for training and validation\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 3600 #1200 training samples for each class\n",
    "nb_validation_samples = 1200 #400 training samples for each class\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "#Get the bottleneck features by  Weights.T * Xi\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    #Load the pre trained VGG16 model from Keras, we will initialize only the convolution layers and ignore the top layers.\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(train_data_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode=None, #class_mode=None means the generator won't load the class labels.\n",
    "                                            shuffle=False) #We won't shuffle the data, because we want the class labels to stay in order.\n",
    "    bottleneck_features_train = model.predict_generator(generator, nb_train_samples // batch_size)\n",
    "    np.save('bottleneck_features_train.npy',bottleneck_features_train) #bottleneck_features_train is a numpy array\n",
    "\n",
    "    generator = datagen.flow_from_directory(validation_data_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode=None,\n",
    "                                            shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples // batch_size)\n",
    "    np.save('bottleneck_features_validation.npy',bottleneck_features_validation)\n",
    "    print(\"Got the bottleneck features in time: \",dt.now()-global_start)\n",
    "    \n",
    "save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 8,457,475\n",
      "Trainable params: 8,456,451\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "Train on 3600 samples, validate on 1200 samples\n",
      "Epoch 1/50\n",
      "3600/3600 [==============================] - 51s 14ms/step - loss: 40.7390 - acc: 0.8575 - val_loss: 26.2467 - val_acc: 0.9758\n",
      "Epoch 2/50\n",
      "3600/3600 [==============================] - 46s 13ms/step - loss: 18.9521 - acc: 0.9544 - val_loss: 13.9537 - val_acc: 0.9517\n",
      "Epoch 3/50\n",
      "3600/3600 [==============================] - 46s 13ms/step - loss: 11.3191 - acc: 0.9647 - val_loss: 9.3567 - val_acc: 0.9283\n",
      "Epoch 4/50\n",
      "3600/3600 [==============================] - 47s 13ms/step - loss: 8.0497 - acc: 0.9667 - val_loss: 7.4151 - val_acc: 0.8817\n",
      "Epoch 5/50\n",
      "3600/3600 [==============================] - 45s 13ms/step - loss: 6.4760 - acc: 0.9739 - val_loss: 5.9318 - val_acc: 0.9483\n",
      "Epoch 6/50\n",
      "3600/3600 [==============================] - 45s 13ms/step - loss: 5.5140 - acc: 0.9731 - val_loss: 5.3999 - val_acc: 0.9058\n",
      "Epoch 7/50\n",
      "3600/3600 [==============================] - 46s 13ms/step - loss: 4.9870 - acc: 0.9608 - val_loss: 4.8157 - val_acc: 0.9392\n",
      "Epoch 8/50\n",
      "3600/3600 [==============================] - 47s 13ms/step - loss: 4.5215 - acc: 0.9622 - val_loss: 5.6115 - val_acc: 0.7333\n",
      "Epoch 9/50\n",
      "3600/3600 [==============================] - 45s 13ms/step - loss: 4.1880 - acc: 0.9622 - val_loss: 4.2228 - val_acc: 0.9467\n",
      "Epoch 10/50\n",
      "3600/3600 [==============================] - 47s 13ms/step - loss: 3.8999 - acc: 0.9597 - val_loss: 3.8552 - val_acc: 0.9242\n",
      "Epoch 11/50\n",
      "3600/3600 [==============================] - 46s 13ms/step - loss: 3.6391 - acc: 0.9636 - val_loss: 3.5214 - val_acc: 0.9392\n",
      "Epoch 12/50\n",
      "3600/3600 [==============================] - 46s 13ms/step - loss: 3.3965 - acc: 0.9672 - val_loss: 3.7656 - val_acc: 0.8533\n",
      "Epoch 13/50\n",
      "3600/3600 [==============================] - 46s 13ms/step - loss: 3.2731 - acc: 0.9558 - val_loss: 3.4724 - val_acc: 0.8925\n",
      "Epoch 14/50\n",
      "3600/3600 [==============================] - 45s 12ms/step - loss: 3.0930 - acc: 0.9606 - val_loss: 3.2294 - val_acc: 0.9000\n",
      "Epoch 15/50\n",
      "3600/3600 [==============================] - 45s 13ms/step - loss: 2.9201 - acc: 0.9589 - val_loss: 3.0189 - val_acc: 0.9625\n",
      "Epoch 16/50\n",
      "3600/3600 [==============================] - 45s 13ms/step - loss: 2.8428 - acc: 0.9564 - val_loss: 3.1538 - val_acc: 0.8475\n",
      "Epoch 17/50\n",
      "3600/3600 [==============================] - 46s 13ms/step - loss: 2.7067 - acc: 0.9581 - val_loss: 2.8284 - val_acc: 0.9175\n",
      "Epoch 18/50\n",
      "3600/3600 [==============================] - 47s 13ms/step - loss: 2.5443 - acc: 0.9631 - val_loss: 2.5982 - val_acc: 0.9425\n",
      "Epoch 19/50\n",
      "3600/3600 [==============================] - 46s 13ms/step - loss: 2.4583 - acc: 0.9581 - val_loss: 2.9160 - val_acc: 0.8658\n",
      "Epoch 20/50\n",
      "3264/3600 [==========================>...] - ETA: 3s - loss: 2.3727 - acc: 0.9596"
     ]
    }
   ],
   "source": [
    "#After we get the bottleneck features, we will build the top fully connected layers on top of the bottlneck features. Let's build the top layers.\n",
    "def train_top_model():\n",
    "    global_start=dt.now()\n",
    "\n",
    "    train_data = np.load('bottleneck_features_train.npy')\n",
    "    train_labels = np.array([0] * (nb_train_samples // 3) + [1] * (nb_train_samples // 3) + [2] * (nb_train_samples // 3)) #Equivalent to: np.array([0]*1200 + [1]*1200 + [2]*1200)\n",
    "\n",
    "    validation_data = np.load('bottleneck_features_validation.npy')\n",
    "    validation_labels = np.array([0] * (nb_validation_samples // 3) + [1] * (nb_validation_samples // 3) + [2] * (nb_validation_samples // 3))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:])) #Ignore the first index. It contains ID\n",
    "\n",
    "    model.add(Dense(256, activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001))) #Best weight initializer for relu is he_normal\n",
    "    model.add(BatchNormalization()) #Add a BatchNormalization layer to control internel covariance shift\n",
    "    model.add(Dropout(rate=0.5)) #Using droput for regularization\n",
    "\n",
    "    model.add(Dense(256, activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001)))\n",
    "    model.add(BatchNormalization()) #Add a BatchNormalization layer to control internel covariance shift\n",
    "    model.add(Dropout(rate=0.5))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax',kernel_initializer='glorot_uniform')) #Because we have 3 classes. Remember, softmax is to multi-class, what sigmoid (log reg) is to binary\n",
    "\n",
    "    optim=RMSprop(lr=0.0001, epsilon=1e-8, decay=1e-6)\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer=optim,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    model.fit(x=train_data,\n",
    "              y=train_labels,\n",
    "              epochs=epochs,\n",
    "              validation_data=(validation_data, validation_labels))    \n",
    "    model.save_weights('bottleneck_feats_multi_weights.h5') \n",
    "    model.save('bottleneck_feats_multi_model.h5')\n",
    "    print(\"The top layer trained in time: \",dt.now()-global_start)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model=train_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to plot/update the train and test loss after each epoch.\n",
    "def plt_dynamic_loss(x, vy, ty, ax, colors=['b']):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()\n",
    "\n",
    "#Get model history\n",
    "history=model.history\n",
    "\n",
    "'''#Plot the train and test loss vs number of epochs\n",
    "score = model.evaluate(X_test, y_test, verbose=0) \n",
    "print('Test score (Validation Loss):', score[0]) \n",
    "print('Test accuracy (Accuracy on Unseen Data):', score[1])'''\n",
    "\n",
    "#Plot train vs test loss\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('Epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "#List of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "#Display the loss\n",
    "val_loss = history.history['val_loss'] #Validation Loss\n",
    "loss = history.history['loss'] #Training Loss\n",
    "plt_dynamic_loss(x, val_loss, loss, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = './models/model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2e44965be891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#Load the pre-trained models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = './models/model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.models import Sequential, load_model\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#Load the pre-trained models\n",
    "model = load_model('bottleneck_feats_multi_model.h5')\n",
    "model.load_weights('bottleneck_feats_multi_weights.h5')\n",
    "\n",
    "#Define image parameters. This should be same as the dimensions of the input image\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "#Make predictions using this function. Call this function with the file name\n",
    "def predict(file):\n",
    "    img = load_img(file, target_size=(img_width,img_height))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    array = model.predict(img)\n",
    "    result = array[0]\n",
    "    #print(result)\n",
    "    answer = np.argmax(result)\n",
    "    if answer == 1:\n",
    "        print(\"Predicted: Tiger.\")\n",
    "    elif answer == 0:\n",
    "        print(\"Predicted: Horse\")\n",
    "    elif answer == 2:\n",
    "        print(\"Predicted: Monkey\")\n",
    "\n",
    "    return answer\n",
    "\n",
    "#Walk the directory for every image\n",
    "for i, ret in enumerate(os.walk(test_path)):\n",
    "    for i, filename in enumerate(ret[2]):\n",
    "    if filename.startswith(\".\"):\n",
    "        continue\n",
    "    \n",
    "    print(ret[0] + '/' + filename)\n",
    "    result = predict(ret[0] + '/' + filename)\n",
    "    print(\" \")\n",
    "\n",
    "#Calculate execution time\n",
    "end = time.time()\n",
    "dur = end-start\n",
    "\n",
    "if dur<60:\n",
    "    print(\"Execution Time:\",dur,\"seconds\")\n",
    "elif dur>60 and dur<3600:\n",
    "    dur=dur/60\n",
    "    print(\"Execution Time:\",dur,\"minutes\")\n",
    "else:\n",
    "    dur=dur/(60*60)\n",
    "print(\"Execution Time:\",dur,\"hours\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
