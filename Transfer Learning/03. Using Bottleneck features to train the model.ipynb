{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras import applications\n",
    "from datetime import datetime as dt\n",
    "from keras import regularizers as reg\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3600 images belonging to 3 classes.\n",
      "Found 1200 images belonging to 3 classes.\n",
      "Got the bottleneck features in time:  1:21:46.450842\n"
     ]
    }
   ],
   "source": [
    "global_start=dt.now()\n",
    "\n",
    "#Dimensions of our flicker images is 256 X 256\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "#Declaration of parameters needed for training and validation\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "epochs = 40\n",
    "batch_size = 16\n",
    "\n",
    "#Get the bottleneck features by  Weights.T * Xi\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    #Load the pre trained VGG16 model from Keras, we will initialize only the convolution layers and ignore the top layers.\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator_tr = datagen.flow_from_directory(train_data_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode=None, #class_mode=None means the generator won't load the class labels.\n",
    "                                            shuffle=False) #We won't shuffle the data, because we want the class labels to stay in order.\n",
    "    nb_train_samples = len(generator_tr.filenames) #3600. 1200 training samples for each class\n",
    "    bottleneck_features_train = model.predict_generator(generator_tr, nb_train_samples // batch_size)\n",
    "    np.save('weights/bottleneck_features_train.npy',bottleneck_features_train) #bottleneck_features_train is a numpy array\n",
    "\n",
    "    generator_ts = datagen.flow_from_directory(validation_data_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode=None,\n",
    "                                            shuffle=False)\n",
    "    nb_validation_samples = len(generator_ts.filenames) #1200. 400 training samples for each class\n",
    "    bottleneck_features_validation = model.predict_generator(generator_ts, nb_validation_samples // batch_size)\n",
    "    np.save('weights/bottleneck_features_validation.npy',bottleneck_features_validation)\n",
    "    print(\"Got the bottleneck features in time: \",dt.now()-global_start)\n",
    "    \n",
    "    num_classes = len(generator_tr.class_indices)\n",
    "    \n",
    "    return nb_train_samples,nb_validation_samples,num_classes,generator_tr,generator_ts\n",
    "    \n",
    "nb_train_samples,nb_validation_samples,num_classes,generator_tr,generator_ts=save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 8,457,475\n",
      "Trainable params: 8,456,451\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "Train on 3600 samples, validate on 1200 samples\n",
      "Epoch 1/40\n",
      "3600/3600 [==============================] - 31s 8ms/step - loss: 40.8853 - acc: 0.8517 - val_loss: 26.6112 - val_acc: 0.9425\n",
      "Epoch 2/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 19.3015 - acc: 0.9536 - val_loss: 14.4666 - val_acc: 0.9383\n",
      "Epoch 3/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 11.8598 - acc: 0.9633 - val_loss: 10.1774 - val_acc: 0.8867\n",
      "Epoch 4/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 8.7330 - acc: 0.9658 - val_loss: 7.7163 - val_acc: 0.9425\n",
      "Epoch 5/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 7.0726 - acc: 0.9594 - val_loss: 6.5417 - val_acc: 0.9350\n",
      "Epoch 6/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 5.9594 - acc: 0.9603 - val_loss: 5.6825 - val_acc: 0.9583\n",
      "Epoch 7/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 5.2186 - acc: 0.9681 - val_loss: 4.9284 - val_acc: 0.9617\n",
      "Epoch 8/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 4.7182 - acc: 0.9625 - val_loss: 4.7323 - val_acc: 0.9150\n",
      "Epoch 9/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 4.3416 - acc: 0.9656 - val_loss: 4.3990 - val_acc: 0.9617\n",
      "Epoch 10/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 4.1243 - acc: 0.9611 - val_loss: 4.1259 - val_acc: 0.9250\n",
      "Epoch 11/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 3.8031 - acc: 0.9683 - val_loss: 4.1524 - val_acc: 0.8625\n",
      "Epoch 12/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 3.6046 - acc: 0.9606 - val_loss: 3.4903 - val_acc: 0.9675\n",
      "Epoch 13/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 3.4574 - acc: 0.9558 - val_loss: 3.3901 - val_acc: 0.9400\n",
      "Epoch 14/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 3.2402 - acc: 0.9594 - val_loss: 3.3369 - val_acc: 0.9625\n",
      "Epoch 15/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 3.1462 - acc: 0.9606 - val_loss: 3.0633 - val_acc: 0.9400\n",
      "Epoch 16/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 3.0171 - acc: 0.9517 - val_loss: 3.2838 - val_acc: 0.8933\n",
      "Epoch 17/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 2.8829 - acc: 0.9522 - val_loss: 3.1031 - val_acc: 0.8833\n",
      "Epoch 18/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 2.7739 - acc: 0.9531 - val_loss: 2.7924 - val_acc: 0.9575\n",
      "Epoch 19/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 2.6252 - acc: 0.9586 - val_loss: 3.0955 - val_acc: 0.8642\n",
      "Epoch 20/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 2.4905 - acc: 0.9597 - val_loss: 2.6032 - val_acc: 0.9358\n",
      "Epoch 21/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 2.4215 - acc: 0.9553 - val_loss: 3.7194 - val_acc: 0.7042\n",
      "Epoch 22/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 2.3131 - acc: 0.9603 - val_loss: 2.4647 - val_acc: 0.9517\n",
      "Epoch 23/40\n",
      "3600/3600 [==============================] - 27s 8ms/step - loss: 2.1814 - acc: 0.9628 - val_loss: 2.3097 - val_acc: 0.9417\n",
      "Epoch 24/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 2.1578 - acc: 0.9600 - val_loss: 2.2042 - val_acc: 0.9350\n",
      "Epoch 25/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 2.0521 - acc: 0.9597 - val_loss: 2.2994 - val_acc: 0.8725\n",
      "Epoch 26/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 1.9197 - acc: 0.9650 - val_loss: 1.9658 - val_acc: 0.9667\n",
      "Epoch 27/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 1.9475 - acc: 0.9578 - val_loss: 2.7461 - val_acc: 0.7025\n",
      "Epoch 28/40\n",
      "3600/3600 [==============================] - 29s 8ms/step - loss: 1.7969 - acc: 0.9586 - val_loss: 2.9377 - val_acc: 0.7508\n",
      "Epoch 29/40\n",
      "3600/3600 [==============================] - 28s 8ms/step - loss: 1.8114 - acc: 0.9586 - val_loss: 2.1315 - val_acc: 0.9308\n",
      "Epoch 30/40\n",
      "3600/3600 [==============================] - 28s 8ms/step - loss: 1.8113 - acc: 0.9619 - val_loss: 1.9936 - val_acc: 0.9092\n",
      "Epoch 31/40\n",
      "3600/3600 [==============================] - 27s 8ms/step - loss: 1.7348 - acc: 0.9603 - val_loss: 1.5782 - val_acc: 0.9667\n",
      "Epoch 32/40\n",
      "3600/3600 [==============================] - 28s 8ms/step - loss: 1.6240 - acc: 0.9644 - val_loss: 2.0490 - val_acc: 0.8392\n",
      "Epoch 33/40\n",
      "3600/3600 [==============================] - 27s 8ms/step - loss: 1.6376 - acc: 0.9556 - val_loss: 2.4455 - val_acc: 0.8200\n",
      "Epoch 34/40\n",
      "3600/3600 [==============================] - 27s 8ms/step - loss: 1.6383 - acc: 0.9606 - val_loss: 1.6243 - val_acc: 0.9558\n",
      "Epoch 35/40\n",
      "3600/3600 [==============================] - 27s 8ms/step - loss: 1.5568 - acc: 0.9622 - val_loss: 1.7377 - val_acc: 0.9133\n",
      "Epoch 36/40\n",
      "3600/3600 [==============================] - 28s 8ms/step - loss: 1.5711 - acc: 0.9578 - val_loss: 1.9383 - val_acc: 0.8400\n",
      "Epoch 37/40\n",
      "3600/3600 [==============================] - 27s 8ms/step - loss: 1.3993 - acc: 0.9697 - val_loss: 1.6335 - val_acc: 0.9200\n",
      "Epoch 38/40\n",
      "3600/3600 [==============================] - 27s 8ms/step - loss: 1.4336 - acc: 0.9561 - val_loss: 1.4210 - val_acc: 0.9567\n",
      "Epoch 39/40\n",
      "3600/3600 [==============================] - 27s 8ms/step - loss: 1.3814 - acc: 0.9583 - val_loss: 1.6515 - val_acc: 0.9017\n",
      "Epoch 40/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 1.3657 - acc: 0.9608 - val_loss: 1.3800 - val_acc: 0.9525\n",
      "The top layer trained in time:  0:17:55.819377\n"
     ]
    }
   ],
   "source": [
    "#After we get the bottleneck features, we will build the top fully connected layers on top of the bottlneck features. Let's build the top layers.\n",
    "def train_top_model():\n",
    "    global_start=dt.now()\n",
    "\n",
    "    train_data = np.load('weights/bottleneck_features_train.npy')\n",
    "    validation_data = np.load('weights/bottleneck_features_validation.npy')\n",
    "    \n",
    "    #train_labels = np.array([0] * (nb_train_samples // 3) + [1] * (nb_train_samples // 3) + [2] * (nb_train_samples // 3)) #Equivalent to: np.array([0]*1200 + [1]*1200 + [2]*1200)\n",
    "    #validation_labels = np.array([0] * (nb_validation_samples // 3) + [1] * (nb_validation_samples // 3) + [2] * (nb_validation_samples // 3))\n",
    "    train_labels=generator_tr.classes  \n",
    "    validation_labels=generator_ts.classes\n",
    "    \n",
    "    train_labels = to_categorical(train_labels, num_classes=num_classes)  \n",
    "    validation_labels = to_categorical(validation_labels, num_classes=num_classes)  \n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:])) #Ignore the first index. It contains ID\n",
    "\n",
    "    model.add(Dense(256, activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001))) #Best weight initializer for relu is he_normal\n",
    "    model.add(BatchNormalization()) #Add a BatchNormalization layer to control internel covariance shift\n",
    "    model.add(Dropout(rate=0.5)) #Using droput for regularization\n",
    "\n",
    "    model.add(Dense(256, activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001)))\n",
    "    model.add(BatchNormalization()) #Add a BatchNormalization layer to control internel covariance shift\n",
    "    model.add(Dropout(rate=0.5))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax',kernel_initializer='glorot_uniform')) #Because we have 3 classes. Remember, softmax is to multi-class, what sigmoid (log reg) is to binary\n",
    "\n",
    "    optim=RMSprop(lr=0.0001, epsilon=1e-8, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optim,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    model.fit(x=train_data,\n",
    "              y=train_labels,\n",
    "              epochs=epochs,\n",
    "              validation_data=(validation_data, validation_labels))    \n",
    "    model.save_weights('weights/bottleneck_feats_multi_weights.h5') \n",
    "    model.save('weights/bottleneck_feats_multi_model.h5')\n",
    "    print(\"The top layer trained in time: \",dt.now()-global_start)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model=train_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This function is used to plot/update the train and test loss after each epoch.\n",
    "import matplotlib.pyplot as plt\n",
    "def plt_dynamic_loss(x, vy, ty, ax, colors=['b']):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()\n",
    "\n",
    "#Get model history\n",
    "history=model.history\n",
    "\n",
    "'''#Plot the train and test loss vs number of epochs\n",
    "score = model.evaluate(X_test, y_test, verbose=0) \n",
    "print('Test score (Validation Loss):', score[0]) \n",
    "print('Test accuracy (Accuracy on Unseen Data):', score[1])'''\n",
    "\n",
    "#Plot train vs test loss\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('Epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "#List of epoch numbers\n",
    "x = list(range(1,epochs+1))\n",
    "\n",
    "#Display the loss\n",
    "val_loss = history.history['val_loss'] #Validation Loss\n",
    "loss = history.history['loss'] #Training Loss\n",
    "plt_dynamic_loss(x, val_loss, loss, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a Horse!\n",
      "\n",
      "Test Time:  4.04 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.models import Sequential, load_model\n",
    "import time\n",
    "\n",
    "\n",
    "#Define image parameters. This should be same as the dimensions of the input image\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "#Make predictions using this function. Call this function with the file name\n",
    "def predict_image(file):\n",
    "    start = time.time()\n",
    "    test_image = load_img(file, target_size=(img_width,img_height))\n",
    "    test_image = img_to_array(test_image)\n",
    "    test_image = test_image / 255.0\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    bottleneck_prediction = model.predict(test_image)  \n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=bottleneck_prediction.shape[1:])) #Ignore the first index. It contains ID\n",
    "\n",
    "    model.add(Dense(256, activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001))) #Best weight initializer for relu is he_normal\n",
    "    model.add(BatchNormalization()) #Add a BatchNormalization layer to control internel covariance shift\n",
    "    model.add(Dropout(rate=0.5)) #Using droput for regularization\n",
    "\n",
    "    model.add(Dense(256, activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001)))\n",
    "    model.add(BatchNormalization()) #Add a BatchNormalization layer to control internel covariance shift\n",
    "    model.add(Dropout(rate=0.5))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax',kernel_initializer='glorot_uniform')) #Because we have 3 classes. Remember, softmax is to multi-class, what sigmoid (log reg) is to binary\n",
    "\n",
    "    path='weights/bottleneck_feats_multi_weights.h5'\n",
    "    model.load_weights(path)\n",
    "\n",
    "    result = model.predict_classes(bottleneck_prediction) \n",
    "    \n",
    "    if result[0] == 0:\n",
    "        print(\"It's a Horse!\")\n",
    "    elif result[0] == 1:\n",
    "        print(\"It's a Monkey!\")\n",
    "    elif result[0] == 2:\n",
    "        print(\"It's a Tiger!\")\n",
    "        \n",
    "    #Calculate execution time\n",
    "    print(\"\\nTest Time: \",np.round(time.time()-start,2),\"seconds\")\n",
    "\n",
    "predict_image(\"test/006.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
