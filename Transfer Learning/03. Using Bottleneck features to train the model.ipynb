{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Found 3600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "global_start=dt.now()\n",
    "\n",
    "#Dimensions of our flicker images is 256 X 256\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "#Declaration of parameters needed for training and validation\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 3600 #1200 training samples for each class\n",
    "nb_validation_samples = 1200 #400 training samples for each class\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "#Get the bottleneck features by  Weights.T * Xi\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    #Load the pre trained VGG16 model from Keras, we will initialize only the convolution layers and ignore the top layers.\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(train_data_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode=None, #class_mode=None means the generator won't load the class labels.\n",
    "                                            shuffle=False) #We won't shuffle the data, because we want the class labels to stay in order.\n",
    "    bottleneck_features_train = model.predict_generator(generator, nb_train_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_train.npy', 'w'),bottleneck_features_train) #bottleneck_features_train is a numpy array\n",
    "\n",
    "    generator = datagen.flow_from_directory(validation_data_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode=None,\n",
    "                                            shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_validation.npy', 'w'),bottleneck_features_validation)\n",
    "    print(\"Got the bottleneck features in time: \",dt.now()-global_start)\n",
    "    \n",
    "save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_start=dt.now()\n",
    "#After we get the bottleneck features, we will build the top fully connected layers on top of the bottlneck features. Let's build the top layers.\n",
    "def train_top_model():\n",
    "    train_data = np.load(open('bottleneck_features_train.npy'))\n",
    "    train_labels = np.array([0] * (nb_train_samples / 3) + [1] * (nb_train_samples / 3) + [2] * (nb_train_samples / 3))\n",
    "\n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy'))\n",
    "    validation_labels = np.array([0] * (nb_validation_samples / 3) + [1] * (nb_validation_samples / 3) + [2] * (nb_train_samples / 3))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu',kernel_initializer='he_normal')) #Best weight initializer for relu is he_normal\n",
    "    model.add(BatchNormalization()) #Add a BatchNormalization layer to control internel covariance shift\n",
    "    model.add(Dropout(rate=0.5)) #Using droput for regularization\n",
    "    \n",
    "    model.add(Dense(256, activation='relu',kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization()) #Add a BatchNormalization layer to control internel covariance shift\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(3, activation='softmax')) #Because we have 3 classes. Remember, softmax is to multi-class, what sigmoid (log reg) is to binary\n",
    "\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))    \n",
    "    model.save_weights('bottleneck_feats_multi_weights.h5') \n",
    "    model.save('bottleneck_feats_multi_model.h5')\n",
    "    print(\"The top layer trained in time: \",dt.now()-global_start)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model=train_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to plot/update the train and test loss after each epoch.\n",
    "def plt_dynamic_loss(x, vy, ty, ax, colors=['b']):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()\n",
    "\n",
    "#Get model history\n",
    "history=model.history\n",
    "\n",
    "#Plot the train and test loss vs number of epochs\n",
    "score = model.evaluate(X_test, y_test, verbose=0) \n",
    "print('Test score (Validation Loss):', score[0]) \n",
    "print('Test accuracy (Accuracy on Unseen Data):', score[1])\n",
    "\n",
    "#Plot train vs test loss\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('Epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "#List of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "#Display the loss\n",
    "val_loss = history.history['val_loss'] #Validation Loss\n",
    "loss = history.history['loss'] #Training Loss\n",
    "plt_dynamic_loss(x, val_loss, loss, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.models import Sequential, load_model\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#Define Path\n",
    "model_path = './models/model.h5'\n",
    "model_weights_path = './models/weights.h5'\n",
    "test_path = 'data/alien_test'\n",
    "\n",
    "#Load the pre-trained models\n",
    "model = load_model(model_path)\n",
    "model.load_weights(model_weights_path)\n",
    "\n",
    "#Define image parameters\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "#Prediction Function\n",
    "def predict(file):\n",
    "  x = load_img(file, target_size=(img_width,img_height))\n",
    "  x = img_to_array(x)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  array = model.predict(x)\n",
    "  result = array[0]\n",
    "  #print(result)\n",
    "  answer = np.argmax(result)\n",
    "  if answer == 1:\n",
    "    print(\"Predicted: chair\")\n",
    "  elif answer == 0:\n",
    "    print(\"Predicted: Motorbikes\")\n",
    "  elif answer == 2:\n",
    "    print(\"Predicted: soccer_ball\")\n",
    "\n",
    "  return answer\n",
    "\n",
    "#Walk the directory for every image\n",
    "for i, ret in enumerate(os.walk(test_path)):\n",
    "  for i, filename in enumerate(ret[2]):\n",
    "    if filename.startswith(\".\"):\n",
    "      continue\n",
    "    \n",
    "    print(ret[0] + '/' + filename)\n",
    "    result = predict(ret[0] + '/' + filename)\n",
    "    print(\" \")\n",
    "\n",
    "#Calculate execution time\n",
    "end = time.time()\n",
    "dur = end-start\n",
    "\n",
    "if dur<60:\n",
    "    print(\"Execution Time:\",dur,\"seconds\")\n",
    "elif dur>60 and dur<3600:\n",
    "    dur=dur/60\n",
    "    print(\"Execution Time:\",dur,\"minutes\")\n",
    "else:\n",
    "    dur=dur/(60*60)\n",
    "print(\"Execution Time:\",dur,\"hours\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
