{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras import applications\n",
    "from datetime import datetime as dt\n",
    "from keras import regularizers as reg\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_start=dt.now()\n",
    "\n",
    "#Dimensions of our flicker images is 256 X 256\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "#Declaration of parameters needed for training and validation\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 3600 #1200 training samples for each class\n",
    "nb_validation_samples = 1200 #400 training samples for each class\n",
    "epochs = 50\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3600 images belonging to 3 classes.\n",
      "Found 1200 images belonging to 3 classes.\n",
      "Got the bottleneck features in time:  0:45:59.643704\n"
     ]
    }
   ],
   "source": [
    "global_start=dt.now()\n",
    "\n",
    "#Dimensions of our flicker images is 256 X 256\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "#Declaration of parameters needed for training and validation\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 3600 #1200 training samples for each class\n",
    "nb_validation_samples = 1200 #400 training samples for each class\n",
    "epochs = 40\n",
    "batch_size = 16\n",
    "\n",
    "#Get the bottleneck features by  Weights.T * Xi\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    #Load the pre trained VGG16 model from Keras, we will initialize only the convolution layers and ignore the top layers.\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(train_data_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode=None, #class_mode=None means the generator won't load the class labels.\n",
    "                                            shuffle=False) #We won't shuffle the data, because we want the class labels to stay in order.\n",
    "    bottleneck_features_train = model.predict_generator(generator, nb_train_samples // batch_size)\n",
    "    np.save('weights/bottleneck_features_train.npy',bottleneck_features_train) #bottleneck_features_train is a numpy array\n",
    "\n",
    "    generator = datagen.flow_from_directory(validation_data_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode=None,\n",
    "                                            shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples // batch_size)\n",
    "    np.save('weights/bottleneck_features_validation.npy',bottleneck_features_validation)\n",
    "    print(\"Got the bottleneck features in time: \",dt.now()-global_start)\n",
    "    \n",
    "save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 8,457,475\n",
      "Trainable params: 8,456,451\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "Train on 3600 samples, validate on 1200 samples\n",
      "Epoch 1/40\n",
      "3600/3600 [==============================] - 32s 9ms/step - loss: 40.2774 - acc: 0.8661 - val_loss: 25.6107 - val_acc: 0.9592\n",
      "Epoch 2/40\n",
      "3600/3600 [==============================] - 24s 7ms/step - loss: 18.2924 - acc: 0.9564 - val_loss: 14.5051 - val_acc: 0.6883\n",
      "Epoch 3/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 11.3103 - acc: 0.9594 - val_loss: 9.6175 - val_acc: 0.9467\n",
      "Epoch 4/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 8.2880 - acc: 0.9619 - val_loss: 7.4149 - val_acc: 0.9117\n",
      "Epoch 5/40\n",
      "3600/3600 [==============================] - 25s 7ms/step - loss: 6.6622 - acc: 0.9625 - val_loss: 6.0431 - val_acc: 0.9683\n",
      "Epoch 6/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 5.7000 - acc: 0.9664 - val_loss: 5.5711 - val_acc: 0.9367\n",
      "Epoch 7/40\n",
      "3600/3600 [==============================] - 25s 7ms/step - loss: 5.1272 - acc: 0.9644 - val_loss: 4.7396 - val_acc: 0.9708\n",
      "Epoch 8/40\n",
      "3600/3600 [==============================] - 24s 7ms/step - loss: 4.6838 - acc: 0.9631 - val_loss: 4.5228 - val_acc: 0.9683\n",
      "Epoch 9/40\n",
      "3600/3600 [==============================] - 25s 7ms/step - loss: 4.2599 - acc: 0.9631 - val_loss: 4.5045 - val_acc: 0.8892\n",
      "Epoch 10/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 4.0550 - acc: 0.9583 - val_loss: 4.2017 - val_acc: 0.8908\n",
      "Epoch 11/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 3.7948 - acc: 0.9572 - val_loss: 4.2683 - val_acc: 0.7842\n",
      "Epoch 12/40\n",
      "3600/3600 [==============================] - 24s 7ms/step - loss: 3.5317 - acc: 0.9633 - val_loss: 3.7445 - val_acc: 0.9167\n",
      "Epoch 13/40\n",
      "3600/3600 [==============================] - 25s 7ms/step - loss: 3.4134 - acc: 0.9522 - val_loss: 4.6482 - val_acc: 0.6925\n",
      "Epoch 14/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 3.2100 - acc: 0.9603 - val_loss: 4.0824 - val_acc: 0.7792\n",
      "Epoch 15/40\n",
      "3600/3600 [==============================] - 24s 7ms/step - loss: 2.9993 - acc: 0.9594 - val_loss: 3.2997 - val_acc: 0.8600\n",
      "Epoch 16/40\n",
      "3600/3600 [==============================] - 25s 7ms/step - loss: 2.8472 - acc: 0.9586 - val_loss: 2.9477 - val_acc: 0.9317\n",
      "Epoch 17/40\n",
      "3600/3600 [==============================] - 24s 7ms/step - loss: 2.6765 - acc: 0.9622 - val_loss: 2.6215 - val_acc: 0.9517\n",
      "Epoch 18/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 2.5822 - acc: 0.9558 - val_loss: 2.8397 - val_acc: 0.8917\n",
      "Epoch 19/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 2.4790 - acc: 0.9608 - val_loss: 2.7059 - val_acc: 0.8958\n",
      "Epoch 20/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 2.4114 - acc: 0.9597 - val_loss: 3.2736 - val_acc: 0.7858\n",
      "Epoch 21/40\n",
      "3600/3600 [==============================] - 27s 7ms/step - loss: 2.2728 - acc: 0.9644 - val_loss: 2.3299 - val_acc: 0.9075\n",
      "Epoch 22/40\n",
      "3600/3600 [==============================] - 24s 7ms/step - loss: 2.2088 - acc: 0.9553 - val_loss: 2.3603 - val_acc: 0.8875\n",
      "Epoch 23/40\n",
      "3600/3600 [==============================] - 24s 7ms/step - loss: 2.1163 - acc: 0.9578 - val_loss: 2.0765 - val_acc: 0.9542\n",
      "Epoch 24/40\n",
      "3600/3600 [==============================] - 25s 7ms/step - loss: 1.9983 - acc: 0.9597 - val_loss: 2.0854 - val_acc: 0.9533\n",
      "Epoch 25/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 1.9440 - acc: 0.9617 - val_loss: 2.6076 - val_acc: 0.8067\n",
      "Epoch 26/40\n",
      "3600/3600 [==============================] - 24s 7ms/step - loss: 1.9268 - acc: 0.9547 - val_loss: 2.2056 - val_acc: 0.8983\n",
      "Epoch 27/40\n",
      "3600/3600 [==============================] - 24s 7ms/step - loss: 1.8499 - acc: 0.9586 - val_loss: 2.6987 - val_acc: 0.7792\n",
      "Epoch 28/40\n",
      "3600/3600 [==============================] - 25s 7ms/step - loss: 1.7104 - acc: 0.9686 - val_loss: 3.4006 - val_acc: 0.6100\n",
      "Epoch 29/40\n",
      "3600/3600 [==============================] - 25s 7ms/step - loss: 1.6819 - acc: 0.9656 - val_loss: 1.8667 - val_acc: 0.8750\n",
      "Epoch 30/40\n",
      "3600/3600 [==============================] - 25s 7ms/step - loss: 1.6723 - acc: 0.9594 - val_loss: 2.1082 - val_acc: 0.8725\n",
      "Epoch 31/40\n",
      "3600/3600 [==============================] - 24s 7ms/step - loss: 1.6620 - acc: 0.9578 - val_loss: 3.2806 - val_acc: 0.6950\n",
      "Epoch 32/40\n",
      "3600/3600 [==============================] - 25s 7ms/step - loss: 1.6102 - acc: 0.9611 - val_loss: 1.8031 - val_acc: 0.8833\n",
      "Epoch 33/40\n",
      "3600/3600 [==============================] - 25s 7ms/step - loss: 1.5388 - acc: 0.9617 - val_loss: 1.8576 - val_acc: 0.9008\n",
      "Epoch 34/40\n",
      "3600/3600 [==============================] - 24s 7ms/step - loss: 1.5222 - acc: 0.9589 - val_loss: 1.5996 - val_acc: 0.9358\n",
      "Epoch 35/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 1.4756 - acc: 0.9575 - val_loss: 1.5313 - val_acc: 0.9550\n",
      "Epoch 36/40\n",
      "3600/3600 [==============================] - 24s 7ms/step - loss: 1.3959 - acc: 0.9653 - val_loss: 1.3473 - val_acc: 0.9733\n",
      "Epoch 37/40\n",
      "3600/3600 [==============================] - 25s 7ms/step - loss: 1.4146 - acc: 0.9600 - val_loss: 1.3307 - val_acc: 0.9675\n",
      "Epoch 38/40\n",
      "3600/3600 [==============================] - 25s 7ms/step - loss: 1.3492 - acc: 0.9606 - val_loss: 2.2097 - val_acc: 0.7775\n",
      "Epoch 39/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 1.3353 - acc: 0.9608 - val_loss: 1.3379 - val_acc: 0.9483\n",
      "Epoch 40/40\n",
      "3600/3600 [==============================] - 26s 7ms/step - loss: 1.2890 - acc: 0.9656 - val_loss: 1.2943 - val_acc: 0.9508\n",
      "The top layer trained in time:  0:16:59.834630\n"
     ]
    }
   ],
   "source": [
    "#After we get the bottleneck features, we will build the top fully connected layers on top of the bottlneck features. Let's build the top layers.\n",
    "def train_top_model():\n",
    "    global_start=dt.now()\n",
    "\n",
    "    train_data = np.load('weights/bottleneck_features_train.npy')\n",
    "    train_labels = np.array([0] * (nb_train_samples // 3) + [1] * (nb_train_samples // 3) + [2] * (nb_train_samples // 3)) #Equivalent to: np.array([0]*1200 + [1]*1200 + [2]*1200)\n",
    "\n",
    "    validation_data = np.load('weights/bottleneck_features_validation.npy')\n",
    "    validation_labels = np.array([0] * (nb_validation_samples // 3) + [1] * (nb_validation_samples // 3) + [2] * (nb_validation_samples // 3))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:])) #Ignore the first index. It contains ID\n",
    "\n",
    "    model.add(Dense(256, activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001))) #Best weight initializer for relu is he_normal\n",
    "    model.add(BatchNormalization()) #Add a BatchNormalization layer to control internel covariance shift\n",
    "    model.add(Dropout(rate=0.5)) #Using droput for regularization\n",
    "\n",
    "    model.add(Dense(256, activation='relu',kernel_initializer='he_normal',kernel_regularizer=reg.l1_l2(l1=0.001, l2=0.001)))\n",
    "    model.add(BatchNormalization()) #Add a BatchNormalization layer to control internel covariance shift\n",
    "    model.add(Dropout(rate=0.5))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax',kernel_initializer='glorot_uniform')) #Because we have 3 classes. Remember, softmax is to multi-class, what sigmoid (log reg) is to binary\n",
    "\n",
    "    optim=RMSprop(lr=0.0001, epsilon=1e-8, decay=1e-6)\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer=optim,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    model.fit(x=train_data,\n",
    "              y=train_labels,\n",
    "              epochs=epochs,\n",
    "              validation_data=(validation_data, validation_labels))    \n",
    "    model.save_weights('weights/bottleneck_feats_multi_weights.h5') \n",
    "    model.save('weights/bottleneck_feats_multi_model.h5')\n",
    "    print(\"The top layer trained in time: \",dt.now()-global_start)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model=train_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the top model\n",
    "from keras.models import load_model\n",
    "model = load_model('weights/bottleneck_feats_multi_model.h5')\n",
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bb141ef1555a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#Get model history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m '''#Plot the train and test loss vs number of epochs\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "#This function is used to plot/update the train and test loss after each epoch.\n",
    "import matplotlib.pyplot as plt\n",
    "nb_epoch=40\n",
    "def plt_dynamic_loss(x, vy, ty, ax, colors=['b']):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()\n",
    "\n",
    "#Get model history\n",
    "history=model.history\n",
    "\n",
    "'''#Plot the train and test loss vs number of epochs\n",
    "score = model.evaluate(X_test, y_test, verbose=0) \n",
    "print('Test score (Validation Loss):', score[0]) \n",
    "print('Test accuracy (Accuracy on Unseen Data):', score[1])'''\n",
    "\n",
    "#Plot train vs test loss\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('Epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "#List of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "#Display the loss\n",
    "val_loss = history.history['val_loss'] #Validation Loss\n",
    "loss = history.history['loss'] #Training Loss\n",
    "plt_dynamic_loss(x, val_loss, loss, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 5.367101192474365 seconds\n",
      "Execution Time: 5.367101192474365 hours\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.models import Sequential, load_model\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#Load the pre-trained models\n",
    "model = load_model('   bottleneck_feats_multi_model.h5')\n",
    "model.load_weights('bottleneck_feats_multi_weights.h5')\n",
    "\n",
    "#Define image parameters. This should be same as the dimensions of the input image\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "#Make predictions using this function. Call this function with the file name\n",
    "def predict(file):\n",
    "    img = load_img(file, target_size=(img_width,img_height))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    array = model.predict(img)\n",
    "    result = array[0]\n",
    "    #print(result)\n",
    "    answer = np.argmax(result)\n",
    "    if answer == 1:\n",
    "        print(\"Predicted: Tiger.\")\n",
    "    elif answer == 0:\n",
    "        print(\"Predicted: Horse\")\n",
    "    elif answer == 2:\n",
    "        print(\"Predicted: Monkey\")\n",
    "\n",
    "    return answer\n",
    "\n",
    "#Walk the directory for every image\n",
    "for i, ret in enumerate(os.walk(test_path)):\n",
    "    for i, filename in enumerate(ret[2]):\n",
    "        if (filename.startswith(\".\")):\n",
    "            continue\n",
    "    \n",
    "    print(ret[0] + '/' + filename)\n",
    "    result = predict(ret[0] + '/' + filename)\n",
    "    print(\" \")\n",
    "\n",
    "#Calculate execution time\n",
    "end = time.time()\n",
    "dur = end-start\n",
    "\n",
    "if dur<60:\n",
    "    print(\"Execution Time:\",dur,\"seconds\")\n",
    "elif dur>60 and dur<3600:\n",
    "    dur=dur/60\n",
    "    print(\"Execution Time:\",dur,\"minutes\")\n",
    "else:\n",
    "    dur=dur/(60*60)\n",
    "print(\"Execution Time:\",dur,\"hours\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
